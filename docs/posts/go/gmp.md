---
title: gmp模型
description: 关于go gmp模型的知识梳理
date: 2026-01-01
tags:
  - Go
  - Runtime
---

# GMP
## 1. 背景

go引入了goroutine为了解决c10k的问题，传统的并发模型中往往依赖于系统线程提供的能力来解决问题，而thread本身存在占用空间大、上下文切换慢等问题，一般情况下，线程占1mb-8mb，若尝试创建10000个线程，那么就大概占用几百g的内存空间，并且线程的调度需要操作系统内核完成，上下文的切换也存在效率问题，并且内核调度器的视角是线程，其不会对特定编程语言层面做调度上的优化。

go设计者意识到上面的问题，所以在go的设计中引入了用户态线程--goroutine。其设计初衷为了解决以下核心问题：

- **动态栈管理：** Goroutine的初始栈空间极小（Go 1.0时期为4KB，Go 1.2优化为2KB），并能根据需要动态伸缩 。这种设计使得在一个进程内运行数百万个Goroutine成为可能。   
- **廉价的上下文切换：** Goroutine的切换完全在用户态进行，无需陷入内核。调度器只需保存极少量的寄存器（PC, SP, DX等），切换成本仅为纳秒级，仅为OS线程切换开销的十分之一甚至更低 。   
- **同步编程模型，异步执行机制：** Go试图为开发者提供符合人类思维习惯的同步阻塞式编程接口（例如直接调用 `net.Conn.Read`），而运行时（Runtime）底层则利用I/O多路复用（如epoll）将其转化为非阻塞的异步执行，从而屏蔽了复杂的异步回调逻辑 。

Go选择了M:N的线程模型，即M个Goroutine被复用在N个操作系统线程上。这种模型试图结合1:1模型的并行能力和N:1模型的轻量级特性，但其实陈与调度的复杂性也随之而来。

## 2. GMP的演进

Go 1.0及之前的版本采用了一个相对朴素的调度器架构，后世称之为GM模型。这一时期的调度器虽然实现了基本的M:N映射，但在高并发场景下暴露出严重的可扩展性缺陷。
### 2.1 GM模型

GM模型主要由两个核心实体组成：

- **G (Goroutine)：** 代表并发执行的任务单元，包含栈信息、指令指针等状态。
- **M (Machine)：** 代表操作系统内核线程，是执行指令的实体。M由操作系统调度器管理。

在GM模型中，所有的Goroutine都维护在一个单一的**全局运行队列（Global Run Queue, GRQ）**中。任何一个M想要执行任务，都必须从这个全局队列中获取G，如下图所示。

![](../../assets/gm-model.png)
*图 1: GM 调度模型概览*

Dmitry Vyukov在2012年的[设计文档](https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit?tab=t.0#heading=h.mmq8lm48qfcw)中详细剖析了这些问题，这些问题的核心矛盾点在于，g和m耦合太严重，m既是计算资源又是调度资源，于是Dmitry Vyukov在优化的方案中提出了GMP模型并在后续版本（go 1.1）进行了实现。
### 2.2 GMP模型
GMP模型的核心在于引入了第三个实体：**P（Processor）**。 P被定义为“执行Go代码所需的资源上下文”或“逻辑处理器”。在新的模型下：

- **G (Goroutine)：** 待执行的任务。
- **M (Machine)：** 工作线程，负责执行代码。
- **P (Processor)：** 调度上下文，维护本地运行队列。
![](../../assets/gmp-model.png)*图 2: GMP 调度模型概览*

**P的引入解决了什么问题？**

1. **去中心化锁：** 原本的全局运行队列被拆分。每个P拥有一个**本地运行队列**。当M绑定到一个P时，它可以无锁（或极低开销）地访问该P的本地队列，从而消除了全局锁的瓶颈 。   
2. **资源隔离与解耦：** 内存缓存从M移动到了P上。这意味着，当M因为系统调用阻塞时，P可以与M分离，并将P及其持有的mcache资源传递给其他空闲的M使用。这一设计极大地提高了资源利用率 。   

### 2.3 运行时实体关系

在GMP模型中，M必须持有P才能执行Go代码。

- **GOMAXPROCS：** 定义了P的数量，通常默认为CPU核数。这决定了同一时刻并行执行Go代码的最大程度。
- **M与P的绑定：** M是执行者，P是资源。当G执行系统调用导致M阻塞时，P会与M分离，寻找新的M继续执行队列中的其他G，从而实现非阻塞的并发调度。

## 3. 核心调度机制

GMP模型不仅改变了数据结构，还引入了一套复杂的调度算法，以在P去中心化的环境下保持负载均衡。
### 3.1 调度循环

Go调度器的核心是一个循环机制，M在持有P的情况下，不断通过以下优先级顺序寻找可运行的G ：   

1. **Check `runnext`：** 这是一个特殊的、容量为1的高优先级槽位。为了优化通信延迟，当一个G唤醒另一个G时，被唤醒的G会被放入`runnext`，M会优先执行它。
2. **Check Local Run Queue (LRQ)：** M访问绑定P的本地队列。这是最快路径，通常无锁。
3. **Check Global Run Queue (GRQ)：** 为了防止全局队列中的G被“饿死”，调度器会以一定的频率（每61次调度循环）强制检查一次全局队列。
4. **Network Poller：** 检查是否有网络I/O就绪的G。
5. **Work Stealing（工作窃取）：** 如果上述均为空，M会尝试从其他P的本地队列中“窃取”任务。

调度发生的场景和主要调度逻辑如下图所示。
![](../../assets/gmp-schedule.png)
*图 3: 常见调度场景*

### 3.2 核心逻辑

上述调度的逻辑充分展示了go在gmp设计上的局部性优化和公平性保障的理念。
#### 3.2.1 runnext

通过引入runnext结构实现了类似于“线程交接”的效果：如果G1向Channel发送数据唤醒了G2，G2会被放入G1所在P的runnext槽位。这意味着G1让出CPU后，G2几乎能立即执行，极大提升了Pipeline模式下的数据传递效率和CPU缓存局部性（L1/L2 Cache）。
当然，runnext的引入也带来一定的问题，这种优化的代价是之前队列中的老任务面临长时间得不到调度的问题，这就产生了饥饿问题，这种本质上是插队行为，破坏了fifo的绝对公平。
#### 3.2.2 工作窃取

工作窃取机制的引入是为了“本地队列架构”带来的任务分配不均问题，由于p结构式分布式的，所以每个p中执行的任务类型会有所不同，很有可能会出现某个p队列执行的密集计算任务，另外一个p执行io密集任务，大概率上io密集任务会较快执行完成，这也会使某个p的本地队列无任务可执行。上述的核心痛点：
1. **CPU 饥饿：** 避免有任务没人做，有人没事做；
2. **长尾延迟：** 防止某个 P 积压太多任务导致其中的 G 等待过久。
所以工作窃取的设计其实是在局部性与公平性做了平衡，在某种程度上，cpu空转的浪费是比cache miss更难忍受的，所以引入窃取机制可以在一定程度解决上述痛点。
#### 3.2.3 每61次固定检查全局队列

该调度策略的引入是为了打破本地队列垄断的问题，防止全局队列中的任务出现饥饿。在GMP的模型中，P进行检查的优先级为：`runnext` > `本地队列 (Local Runq)` > `全局队列 (Global Runq)` > `网络/偷取`。所以假如不进行强制干涉，那么全局队列中的G会一直得不到执行，这就会造成全局队列饥饿的情况。为了解决上述问题，runtime引入强行打断的机制，即每经过61次调度循环就会访问全局队列来执行G任务。此外，全局队列还承担了**容量溢出兜底**的角色：当 P 的本地队列已满时，部分 G 会被批量转移到全局队列，以平衡负载。
#### 3.2.4 抢占机制

除了上述在常规调度循环中方式外，go还引入了一些特殊的方式来尽量保证整个GMP模型运转的效率性。sysmon线程是一个特殊的M，其运行不需要绑定P并且不受GOMAXPROCS限制，直接运行在系统栈上。其通过下述两种方式进行抢占：
1. **协作式抢占**：通过在函数头部插入一段检查代码，当G调用下一个函数时会检查栈空间，如果发现栈保护字异常，会触发运行时逻辑，从而让出CPU；
2. **异步抢占**：某些函数其逻辑属于密集循环无法通过协作式抢占来强制其让出CPU，所以sysmon通过发送SIGURG信号来解决该问题，从而使密集循环逻辑让出CPU；
无论是何种抢占机制，其阈值都是10ms，即超过10ms时，sysmon会进行抢占，而抢占机制的引入也是GMP模型保证全局公平性的重要特性。

#### 3.2.5 其他机制

当 G 进行网络 I/O 时，G 会被放入 Netpoller（也就是去 epoll/kqueue 等待），**此时 M 是不会阻塞的**，M 会立刻去执行 P 里的下一个 G。
Go 调度器为了低延迟，不会让 M 在没任务时立刻休眠。M 会进行“自旋”（消耗 CPU 空转），积极地寻找可运行的 G。这是“CPU 利用率”与“任务时延”之间的权衡。为了减少线程唤醒的开销，Go 采用了自旋机制。当 M 闲置时，它不会立即陷入内核休眠，而是自旋一段时间，尝试从**全局队列**或 **Netpoller 获取任务**，或者从其他 P **窃取任务**。虽然这浪费了少量 CPU，但换取了极低的任务响应延迟。

## 4. 总结

从上述的设计理念和调度机制中，可以很明显感受到GMP的模型设计一直在做权衡，其引入runnext结构来保证局部性的效率，保证CPU的L1/L2缓存能够被充分利用，又引入了工作窃取和抢占机制来解决饥饿性，同时每61次固定检查全局队列的策略又打破runnext和本地队列的“垄断”。

